# -*- coding: utf-8 -*-
"""18IT097.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jqf88zYhGTT-7AKcj4FgJjHc3dJBBP5o
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

import pandas as pd
import io
#data = pd.read_csv(io.BytesIO(uploaded['housing.csv']))
data = pd.read_csv('/content/housing.csv')
data.info()

data.head()

"""**ENCODING**


1.   Label Encoder
2.   Onehot Encoder

**LABEL ENCODER**
"""

from sklearn.preprocessing import LabelEncoder , OneHotEncoder
data['median_house_value'].value_counts()

le=LabelEncoder()
data['median_house_value']=le.fit_transform(data['median_house_value'])
data['median_house_value'].value_counts()

le.classes_

"""**ONEHOT ENCODER**"""

data['ocean_proximity'].value_counts()

one_hot = OneHotEncoder()
transformed_data = one_hot.fit_transform(data['ocean_proximity'].values.reshape(-1,1)).toarray()
one_hot.categories_

transformed_data = pd.DataFrame(transformed_data , 
                                columns = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY','NEAR OCEAN'])
transformed_data.head()

transformed_data.iloc[90, ]

data['median_house_value'][90]

"""**Normalization & Standardization**"""

numeric_columns = [c for c in data.columns if data[c].dtype != np.dtype('O')]
numeric_columns

len(numeric_columns) , len(data.columns)

numeric_columns.remove('longitude')
numeric_columns.remove('latitude')

temp_data = data[numeric_columns]
temp_data

"""**NORMALIZATION**"""

from sklearn.preprocessing import StandardScaler , MinMaxScaler
import warnings
warnings.filterwarnings('ignore')
normalizer = MinMaxScaler()
temp_data.dropna(axis = 1 , inplace = True)
normalized_data = normalizer.fit_transform(temp_data)
pd.DataFrame(normalized_data , columns = temp_data.columns)

"""**STANDARDIZATION**"""

standard_scaler = StandardScaler()
standardized_data = standard_scaler.fit_transform(temp_data)
pd.DataFrame(standardized_data , columns = temp_data.columns)

"""**Handling with Missing Value**"""

data.isnull().sum()

data['total_bedrooms'].isnull().sum()

"""**Simple Imputer**"""

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(missing_values=np.nan , strategy='mean')
agent_col = imputer.fit_transform(data['total_bedrooms'].values.reshape(-1,1))
pd.DataFrame(agent_col).isnull().sum()

data['total_bedrooms'].isnull().sum()

"""**Discretization**"""

from sklearn.preprocessing import KBinsDiscretizer
temp_data.head()

"""**Quantile Discretization Transform**"""

trans = KBinsDiscretizer(n_bins =10 , encode = 'ordinal' , strategy='quantile')
new_data = trans.fit_transform(temp_data)
pd.DataFrame(new_data,columns = temp_data.columns )

"""**Uniform Discretization Transform**"""

trans = KBinsDiscretizer(n_bins =10 , encode = 'ordinal' , strategy='uniform')
new_data = trans.fit_transform(temp_data)

pd.DataFrame(new_data,columns = temp_data.columns )

"""**KMeans Discretization Transform**"""

trans = KBinsDiscretizer(n_bins =10 , encode = 'ordinal' , strategy='uniform')
new_data = trans.fit_transform(temp_data)

pd.DataFrame(new_data,columns = temp_data.columns )